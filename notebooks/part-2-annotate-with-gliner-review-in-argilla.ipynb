{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82G2vlxphIlD"
   },
   "source": [
    "# üí´  Explore and analyze NER predictions\n",
    "\n",
    "In this tutorial, we will learn to log [spaCy](https://spacy.io/) Name Entity Recognition (NER) predictions.\n",
    "\n",
    "This is useful for:\n",
    "\n",
    "- üßêEvaluating pre-trained models.\n",
    "- üîéSpotting frequent errors both during development and production.\n",
    "- üìàAnnotating records to create an gold-standard evaluation dataset.\n",
    "\n",
    "\n",
    "Reference: https://docs.argilla.io/en/latest/tutorials/notebooks/labelling-tokenclassification-spacy-pretrained.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8phxyG-hIlF"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will learn how to explore and analyze spaCy NER pipelines in an easy way.\n",
    "\n",
    "We will load the [*Gutenberg Time*](https://huggingface.co/datasets/gutenberg_time) dataset from the Hugging Face Hub and use a transformer-based spaCy model for detecting entities in this dataset and log the detected entities into an Argilla dataset. This dataset can be used for exploring the quality of predictions and for creating a new training set, by correcting, adding and validating entities via human annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp0MOU97hIlG"
   },
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gG2ZaK1OhIlG"
   },
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "import spacy\n",
    "from gliner_spacy.pipeline import GlinerSpacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Argilla with HuggingFace Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m api_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m api_key\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mrg\u001b[49m\u001b[38;5;241m.\u001b[39mArgilla(\n\u001b[1;32m      4\u001b[0m     api_url\u001b[38;5;241m=\u001b[39mapi_url,\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rg' is not defined"
     ]
    }
   ],
   "source": [
    "api_url= ''\n",
    "api_key= ''\n",
    "client = rg.Argilla(\n",
    "    api_url=api_url,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Argilla with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dT-F6e7zhIlG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6900?frameborder=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1378a5cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Argilla has been deployed at: http://localhost:6900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default argilla username is 'argilla'\n",
    "# default argilla password is '12345678'\n",
    "# default api_key for argilla on docker is 'argilla.apikey'\n",
    "client = rg.Argilla(\n",
    "    api_url=\"http://localhost:6900\",\n",
    "    api_key=\"argilla.apikey\"\n",
    ")\n",
    "client # Test your login! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEU7UgpthIlH"
   },
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GktYugZxhIlH"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPJ5kkX7hIlH"
   },
   "source": [
    "## Our dataset\n",
    "For this tutorial, our default dataset is the [*Gutenberg Time*](https://huggingface.co/datasets/gutenberg_time) dataset from the Hugging Face Hub. It contains all explicit time references in a dataset of 52,183 novels whose full text is available via Project Gutenberg. From extracts of novels, we are surely going to find some NER entities.\n",
    "\n",
    "If you are following the full lab, you can also load the dataset you generated in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MEURV43lhIlH",
    "outputId": "c8ef60fe-55d6-441f-b65b-a2ce6e3801cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0      Dress, Shoes, and Scarf provided by ModCloth.   \n",
      "1      Dress, Shoes, and Scarf provided by ModCloth.   \n",
      "2                   Clothing for both Men and Women.   \n",
      "3  Please dress appropriately for varied weather ...   \n",
      "4  Jackets ‚Äì warm down jacket, a lightweight jack...   \n",
      "\n",
      "                                              output  \\\n",
      "0  ['Dress <> Clothing Item <> A garment worn by ...   \n",
      "1  ['ModCloth <> Clothing Retailer <> A company t...   \n",
      "2  ['Clothing <> Product <> Items worn on the bod...   \n",
      "3  ['varied weather conditions <> Weather <> Envi...   \n",
      "4  ['Jackets <> Clothing Item <> A piece of cloth...   \n",
      "\n",
      "                                          embeddings  \n",
      "0  [0.02724652737379074, 0.0037798627745360136, 0...  \n",
      "1  [0.02724652737379074, 0.0037798627745360136, 0...  \n",
      "2  [0.03369726613163948, 0.020493067800998688, -0...  \n",
      "3  [-0.03423319756984711, 0.018985847011208534, -...  \n",
      "4  [-0.04015563800930977, -0.061232659965753555, ...  \n"
     ]
    }
   ],
   "source": [
    "# when using this notebook standalone, choose a dataset from the hub\n",
    "# dataset = load_dataset(\"gutenberg_time\", split=\"train\", streaming=True)\n",
    "\n",
    "# when using this notebook as part of the full lab, load the dataset you created in the previous step\n",
    "DATASET_PATH = 'data/sampled_dataset/'\n",
    "dataset = load_from_disk(DATASET_PATH)\n",
    "\n",
    "# Let's have a look at the first 5 examples of the train set.\n",
    "try:\n",
    "    print(pd.DataFrame(dataset.take(5)))\n",
    "except AttributeError:\n",
    "    print(pd.DataFrame(dataset[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVmbkS2WhIlH"
   },
   "source": [
    "## Annotating with GLiNER and Logging NER entities into Argilla\n",
    "\n",
    "\n",
    "Let's instantiate a spaCy transformer `nlp` pipeline and apply it to the first N examples in our dataset, collecting the *tokens* and *NER entities*.\n",
    "\n",
    "We're going to use a [GLiNER](https://github.com/urchade/GLiNER) model to perform zero shot NER. This means we can provide any entity labels we like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ba59e79a4c4c48b2f636d09e3bb7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egemenipek/miniconda3/envs/zero-shot-ner-lab/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates person\n",
      "Microsoft organization\n"
     ]
    }
   ],
   "source": [
    "# observe how gliner works\n",
    "\n",
    "# Gliner model options https://huggingface.co/urchade \n",
    "gliner_model = \"urchade/gliner_largev2\"\n",
    "\n",
    "# Define your domain here: the list of entity types you expect to see\n",
    "zero_shot_labels = [\"person\", \"organization\", \"email\", \"sports team\", \"business\"]\n",
    "\n",
    "# Configuration for GLiNER integration\n",
    "custom_spacy_config = {\n",
    "    \"gliner_model\": gliner_model,\n",
    "    \"chunk_size\": 250,\n",
    "    \"labels\": zero_shot_labels,\n",
    "    \"style\": \"ent\"\n",
    "}\n",
    "\n",
    "# Initialize a blank English spaCy pipeline and add GLiNER\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"gliner_spacy\", config=custom_spacy_config)\n",
    "\n",
    "# Example\n",
    "text = \"This is a text about Bill Gates and Microsoft.\"\n",
    "\n",
    "# Process the text with the pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "# Output detected entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create Argilla Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you restart kernel and want to continue from here, get the variable set again\n",
    "# because the created dataset will persist and you'll get an error trying to recreate the argilla_dataset variable from scratch\n",
    "for dataset in client.datasets.list():\n",
    "    if dataset.name == \"argilla_dataset\":\n",
    "        argilla_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you'd like to delete argilla_dataset and start over, just run this cell\n",
    "\n",
    "dataset_to_delete = client.datasets(name=\"argilla_dataset\")\n",
    "\n",
    "dataset_deleted = dataset_to_delete.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"gutenberg_spacy_ner\"\n",
    "dataset_name = \"argilla_dataset\"\n",
    "# define the labels you will be using for this lab\n",
    "labels = ['clothing', 'organization', 'address', 'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50800f6025d54fc8869be9648cceaa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egemenipek/miniconda3/envs/zero-shot-ner-lab/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gliner_spacy.pipeline.GlinerSpacy at 0x3fb43a3e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gliner_model = \"urchade/gliner_largev2\"\n",
    "\n",
    "# Configuration for GLiNER integration with the labels defined above\n",
    "import spacy\n",
    "custom_spacy_config = {\n",
    "    \"gliner_model\": gliner_model,\n",
    "    \"chunk_size\": 250,\n",
    "    \"labels\": labels,\n",
    "    \"style\": \"ent\"\n",
    "}\n",
    "\n",
    "# Initialize a blank English spaCy pipeline and add GLiNER\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"gliner_spacy\", config=custom_spacy_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create settings for Argilla\n",
    "settings = rg.Settings(\n",
    "    guidelines=\"Classify individual tokens into given labels\",\n",
    "    fields = [\n",
    "        rg.TextField(\n",
    "            name='text', # give it a name\n",
    "            title='Text', # this will be displayed on the UI above the text field\n",
    "            use_markdown=False # not necessary for this application\n",
    "        )\n",
    "    ],\n",
    "    # In Argilla a question is basically an annotation instance.\n",
    "    # This is a token classification case and Argilla has a built-in question type for that called the SpanQuestion.\n",
    "    questions=[\n",
    "        rg.SpanQuestion( \n",
    "            name=\"span_label\",\n",
    "            field='text',\n",
    "            labels=labels,\n",
    "            title=\"Classify individual tokens into given labels\",\n",
    "            allow_overlapping=False\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egemenipek/miniconda3/envs/zero-shot-ner-lab/lib/python3.10/site-packages/argilla/datasets/_resource.py:264: UserWarning: Workspace not provided. Using default workspace: default id: cf04c60d-319c-423e-b686-914e4f1a7ace\n",
      "  warnings.warn(f\"Workspace not provided. Using default workspace: {workspace.name} id: {workspace.id}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(id=UUID('28b7237b-23b6-4ad1-9a29-83b2c0e0c2c2') inserted_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 674340) updated_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 710644) name='argilla_dataset' status='ready' guidelines='Classify individual tokens into given labels' allow_extra_metadata=False distribution=OverlapTaskDistributionModel(strategy='overlap', min_submitted=1) workspace_id=UUID('cf04c60d-319c-423e-b686-914e4f1a7ace') last_activity_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 710644))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create argilla dataset\n",
    "argilla_dataset = rg.Dataset(\n",
    "    name=dataset_name,\n",
    "    settings=settings\n",
    ")\n",
    "argilla_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Datasets</h3><table><tr><th>name</th><th>id</th><th>workspace_id</th><th>updated_at</th></tr><tr><td>argilla_dataset</td><td>28b7237b-23b6-4ad1-9a29-83b2c0e0c2c2</td><td>cf04c60d-319c-423e-b686-914e4f1a7ace</td><td>2025-03-13T20:04:45.710644</td></tr></table>"
      ],
      "text/plain": [
       "<argilla.client.Datasets at 0x372cfbd60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe that your dataset is created\n",
    "client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Sending records...: 4batch [00:02,  1.39batch/s]                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetRecords(Dataset(id=UUID('28b7237b-23b6-4ad1-9a29-83b2c0e0c2c2') inserted_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 674340) updated_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 710644) name='argilla_dataset' status='ready' guidelines='Classify individual tokens into given labels' allow_extra_metadata=False distribution=OverlapTaskDistributionModel(strategy='overlap', min_submitted=1) workspace_id=UUID('cf04c60d-319c-423e-b686-914e4f1a7ace') last_activity_at=datetime.datetime(2025, 3, 13, 20, 4, 45, 710644)))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In argilla, you can log what they call 'suggestions' for each data instance\n",
    "# Suggestions are basically model predictions on the data instances\n",
    "\n",
    "# Having these suggestions has two main benefits:\n",
    "# 1. It can help you quickly label your data\n",
    "# 2. You can eyeball the performance of your baseline model\n",
    "\n",
    "# the below function will produce a suggestion output that is acceptable to Argilla from the GLiNER model\n",
    "def gliner_predict(text):\n",
    "    doc = nlp(text)\n",
    "    return [\n",
    "        {\"start\": ent.start_char, \"end\": ent.end_char, \"label\": ent.label_}\n",
    "        for ent in doc.ents\n",
    "    ]\n",
    "\n",
    "# collect all records here\n",
    "record_instances = []\n",
    "for row in dataset:\n",
    "    text = row['input'] # this is the input sequence\n",
    "    span_label= gliner_predict(text) # suggestion data\n",
    "    \n",
    "    # make the record instance acceptable by Argilla token classification task\n",
    "    record_instance = {\n",
    "        'text': text,\n",
    "        'span_label': span_label\n",
    "    }\n",
    "    record_instances.append(record_instance)\n",
    "\n",
    "argilla_dataset.records.log(record_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can now view and annotate your dataset in Argilla.\n",
    "<p>For docker: http://localhost:6900/\n",
    "<p>or visit your space in HF spaces if you opted to use that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Annotated Argilla Dataset\n",
    "\n",
    "GLiNER models return the character indices of the detected entities. For fine-tuning, we need the token indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the dataset to GLiNER training format {'tokenized_text' [], 'ner': [ [start_token_i, end_token_i, label], ...], ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GLiNER annotations as training set\n",
    "train_set = []\n",
    "# use your gold standard as an evaluation set\n",
    "eval_set = []\n",
    "# GLiNER's predictions on the eval set | This will be useful when we start evaluating fine-tuned model against the baseline (GLiNER)\n",
    "baseline_preds = []\n",
    "# training data - strings alone\n",
    "train_set_str = []\n",
    "# evaluation data - strings alone\n",
    "eval_set_str = []\n",
    "\n",
    "for data_point in argilla_dataset.records.to_list(flatten=True):\n",
    "    text = data_point['text'] # get the text out of the data point\n",
    "    tokenized_text = [token.text for token in nlp(text)] # tokenize text with spacy nlp pipeline | this matches GLiNER expectations\n",
    "    if data_point['status'] == 'completed': # this means you have annotated it\n",
    "        annotations = data_point['span_label.responses'][0] # get the annotations\n",
    "        ner = [[annotation['start'], annotation['end'], annotation['label']] for annotation in annotations] # convert annotations to GLiNER expectations\n",
    "        eval_set.append({'tokenized_text': tokenized_text, 'ner': ner}) # append human annotation to the evaluation set\n",
    "        eval_set_str.append(text)\n",
    "\n",
    "        gliner_predictions = data_point['span_label.suggestion'] # get the GLiNER annotation as it's prediction\n",
    "        gliner_ner = [[annotation['start'], annotation['end'], annotation['label']] for annotation in gliner_predictions]\n",
    "        baseline_preds.append({'tokenized_text': tokenized_text, 'ner': gliner_ner})\n",
    "    else: # GLiNER annotations\n",
    "        annotations = data_point['span_label.suggestion'] # get the annotations\n",
    "        ner = [[annotation['start'], annotation['end'], annotation['label']] for annotation in annotations] # convert annotations to GLiNER expectations\n",
    "        train_set.append({'tokenized_text': tokenized_text, 'ner': ner}) # append GLiNER annotation to the training set\n",
    "        train_set_str.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training example: Clothing for both Men and Women. \n",
      "training example: {'tokenized_text': ['Clothing', 'for', 'both', 'Men', 'and', 'Women', '.'], 'ner': [[0, 8, 'clothing']]} \n",
      "evaluation example: In addition this short sleeve tee has raglan sleeves, cover stitched seams and a comfortable tag free neck. \n",
      "evaluation example: {'tokenized_text': ['In', 'addition', 'this', 'short', 'sleeve', 'tee', 'has', 'raglan', 'sleeves', ',', 'cover', 'stitched', 'seams', 'and', 'a', 'comfortable', 'tag', 'free', 'neck', '.'], 'ner': [[17, 33, 'clothing'], [38, 52, 'clothing']]} \n",
      "gliner evaluation example: {'tokenized_text': ['In', 'addition', 'this', 'short', 'sleeve', 'tee', 'has', 'raglan', 'sleeves', ',', 'cover', 'stitched', 'seams', 'and', 'a', 'comfortable', 'tag', 'free', 'neck', '.'], 'ner': [[17, 33, 'clothing'], [38, 52, 'clothing']]}\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(f'training example: {train_set_str[idx]} \\ntraining example: {train_set[idx]} \\nevaluation example: {eval_set_str[idx]} \\nevaluation example: {eval_set[idx]} \\ngliner evaluation example: {baseline_preds[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "import json\n",
    "\n",
    "OUTPUT_ROOT = Path('data/')\n",
    "OUTPUT_ROOT.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "file_path = OUTPUT_ROOT / f\"{dataset_name}_train.jsonl\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for entry in train_set:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')\n",
    "\n",
    "file_path = OUTPUT_ROOT / f\"{dataset_name}_eval.jsonl\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for entry in eval_set:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')\n",
    "\n",
    "file_path = OUTPUT_ROOT / f\"{dataset_name}_baseline_preds.jsonl\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for entry in baseline_preds:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')\n",
    "\n",
    "file_path = OUTPUT_ROOT / f\"{dataset_name}_train_set_str.jsonl\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for entry in train_set_str:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')\n",
    "\n",
    "file_path = OUTPUT_ROOT / f\"{dataset_name}_eval_set_str.jsonl\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for entry in eval_set_str:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A portable bridge had been prepared for crossing the canals which intersected the causeway ; the intention being that it should be laid across a canal , that the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    army\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " should pass over it , and that it should then be carried forward to the next gap in the causeway . This was a most faulty arrangement , necessitating frequent and long delays , and entailing almost certain disaster . Had three such portable bridges been constructed , the column could have crossed the causeway with comparatively little risk ; and there was no reason why these bridges should not have been constructed , as they could have been carried , without difficulty , by the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tlascalans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " . At midnight the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    troops\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " were in readiness for the march . Mass was performed by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Father Olmedo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">person</span>\n",
       "</mark>\n",
       " ; and at one o'clock on July 1st , 1520 , the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Spaniards\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " sallied out from the fortress that they had so stoutly defended . Silence reigned in the city . As noiselessly as possible , the troops made their way down the broad street , expecting every moment to be attacked ; but even the tramping of the horses , and the rumbling of the baggage wagons and artillery did not awake the sleeping \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mexicans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">person</span>\n",
       "</mark>\n",
       " , and the head of the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    column\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " arrived at the head of the causeway before they were discovered . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"tokenized_text\": [\"A\", \"portable\", \"bridge\", \"had\", \"been\", \"prepared\", \"for\", \"crossing\", \"the\", \"canals\", \"which\", \"intersected\", \"the\", \"causeway\", \";\", \"the\", \"intention\", \"being\", \"that\", \"it\", \"should\", \"be\", \"laid\", \"across\", \"a\", \"canal\", \",\", \"that\", \"the\", \"army\", \"should\", \"pass\", \"over\", \"it\", \",\", \"and\", \"that\", \"it\", \"should\", \"then\", \"be\", \"carried\", \"forward\", \"to\", \"the\", \"next\", \"gap\", \"in\", \"the\", \"causeway\", \".\", \"This\", \"was\", \"a\", \"most\", \"faulty\", \"arrangement\", \",\", \"necessitating\", \"frequent\", \"and\", \"long\", \"delays\", \",\", \"and\", \"entailing\", \"almost\", \"certain\", \"disaster\", \".\", \"Had\", \"three\", \"such\", \"portable\", \"bridges\", \"been\", \"constructed\", \",\", \"the\", \"column\", \"could\", \"have\", \"crossed\", \"the\", \"causeway\", \"with\", \"comparatively\", \"little\", \"risk\", \";\", \"and\", \"there\", \"was\", \"no\", \"reason\", \"why\", \"these\", \"bridges\", \"should\", \"not\", \"have\", \"been\", \"constructed\", \",\", \"as\", \"they\", \"could\", \"have\", \"been\", \"carried\", \",\", \"without\", \"difficulty\", \",\", \"by\", \"the\", \"Tlascalans\", \".\", \"At\", \"midnight\", \"the\", \"troops\", \"were\", \"in\", \"readiness\", \"for\", \"the\", \"march\", \".\", \"Mass\", \"was\", \"performed\", \"by\", \"Father\", \"Olmedo\", \";\", \"and\", \"at\", \"one\", \"o'clock\", \"on\", \"July\", \"1st\", \",\", \"1520\", \",\", \"the\", \"Spaniards\", \"sallied\", \"out\", \"from\", \"the\", \"fortress\", \"that\", \"they\", \"had\", \"so\", \"stoutly\", \"defended\", \".\", \"Silence\", \"reigned\", \"in\", \"the\", \"city\", \".\", \"As\", \"noiselessly\", \"as\", \"possible\", \",\", \"the\", \"troops\", \"made\", \"their\", \"way\", \"down\", \"the\", \"broad\", \"street\", \",\", \"expecting\", \"every\", \"moment\", \"to\", \"be\", \"attacked\", \";\", \"but\", \"even\", \"the\", \"tramping\", \"of\", \"the\", \"horses\", \",\", \"and\", \"the\", \"rumbling\", \"of\", \"the\", \"baggage\", \"wagons\", \"and\", \"artillery\", \"did\", \"not\", \"awake\", \"the\", \"sleeping\", \"Mexicans\", \",\", \"and\", \"the\", \"head\", \"of\", \"the\", \"column\", \"arrived\", \"at\", \"the\", \"head\", \"of\", \"the\", \"causeway\", \"before\", \"they\", \"were\", \"discovered\", \".\"], \"ner\": [[29, 30, \"organization\"], [116, 117, \"organization\"], [121, 122, \"organization\"], [133, 135, \"person\"], [147, 148, \"organization\"], [210, 211, \"person\"], [217, 218, \"organization\"]]}\n",
    "#data = train_set[10]\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span, Doc\n",
    "\n",
    "# Create a Doc from the tokenized text\n",
    "doc = Doc(nlp.vocab, words=data[\"tokenized_text\"])\n",
    "ents = []\n",
    "for start, end, label in data[\"ner\"]:\n",
    "    span = Span(doc, start, end, label=label)\n",
    "    ents.append(span)\n",
    "doc.ents = ents\n",
    "\n",
    "# Visualize the NER entities\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8421052631578947\n",
      "Recall: 0.7868852459016393\n",
      "F1: 0.8135593220338982\n"
     ]
    }
   ],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "# below function converts the data to the format that nervaluate expects\n",
    "def convert_data_to_nervaluate_format(data):\n",
    "    formatted_data = []\n",
    "    for data_point in data:\n",
    "        formatted_data_point = [{'label': ner_point[2], 'start': ner_point[0], 'end': ner_point[1]} for ner_point in data_point['ner']]\n",
    "        formatted_data.append(formatted_data_point)\n",
    "    return formatted_data\n",
    "\n",
    "true = convert_data_to_nervaluate_format(eval_set) # human annotated data in the format that nervaluate expects\n",
    "pred = convert_data_to_nervaluate_format(baseline_preds) # GLiNER predictions in the format that nervaluate expects\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=labels)\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "\n",
    "print(f\"Precision: {results['ent_type']['precision']}\\nRecall: {results['ent_type']['recall']}\\nF1: {results['ent_type']['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKuSFsW8hIlI"
   },
   "source": [
    "## Appendix: Log datasets to the Hugging Face Hub\n",
    "\n",
    "Here we will show you an example of how you can push an Argilla dataset (records) to the [Hugging Face Hub](https://huggingface.co/datasets).\n",
    "In this way, you can effectively version any of your Argilla datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how to get your HuggingFace access token here: https://huggingface.co/docs/hub/en/security-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7P0CEANhIlI"
   },
   "outputs": [],
   "source": [
    "# login to huggingface\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "huggingface_access_token = ''\n",
    "\n",
    "login(huggingface_access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push your dataset\n",
    "\n",
    "hf_account_name = ''\n",
    "dataset_name = ''\n",
    "argilla_dataset.to_hub(repo_id=f\"{hf_account_name}/{dataset_name}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "zero-shot-ner-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "metadata": {
   "interpreter": {
    "hash": "0f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
