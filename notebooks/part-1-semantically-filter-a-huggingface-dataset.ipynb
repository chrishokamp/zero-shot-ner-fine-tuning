{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35a3a5-a00e-47ea-ba59-d2b7145aaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a huggingface dataset into a search index, and try semantic filtering for a certain kind of data\n",
    "# Find datasets here: https://huggingface.co/datasets \n",
    "\n",
    "# Relevant Documentation\n",
    "# https://huggingface.co/docs/datasets/en/index \n",
    "# https://huggingface.co/docs/datasets/en/faiss_es\n",
    "# https://www.sbert.net/\n",
    "# https://www.sbert.net/docs/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98b7db-d7a9-4d5f-8cab-64f60981951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Install FAISS with your preferred method (it will be required below)\n",
    "# pip install faiss-cpu\n",
    "# pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8893ec3-3cbf-47dc-b2db-50a5bb49c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset we want to use\n",
    "\n",
    "DATASET_ID = \"numind/NuNER\"\n",
    "\n",
    "# Choose the sentence transformers embedding model we want to use\n",
    "# see here for a list of models: https://www.sbert.net/docs/pretrained_models.html\n",
    "# this model is really fast for symmetric semantic search, with ok quality\n",
    "# EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# this model is pretty good, but it's a lot slower than \"all-MiniLM-L6-v2\"\n",
    "EMBEDDING_MODEL = \"all-mpnet-base-v2\"\n",
    "\n",
    "DEVICE = 'mps' # 'cpu' or 'cuda' or 'mps'\n",
    "# use 'cuda' if you have a graphics unit that has cuda cores (nvidia has them for example)\n",
    "# use mps if you are using an apple machine with an M-series chip\n",
    "# use 'cpu' if the above are not an option, or maybe your graphics unit has very limited memory\n",
    "# or you might just be curious about cpu performance and want to observe it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a2868-552b-484d-9654-9873bcb11203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell may take a while\n",
    "EXAMPLES_TO_INDEX = 100000\n",
    "# note that the slice semantics below still download the full dataset locally\n",
    "# for huge datasets the workflow below would need to be changed to use streaming semantics\n",
    "# available splits for the NuNER dataset are: ['entity', 'full'].\n",
    "ds = load_dataset(DATASET_ID, split=f'full[:{EXAMPLES_TO_INDEX}]', streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cdbc3-3283-42d9-a6d7-3fa0fe1e2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our embedding model, noting the \"device\" kwarg\n",
    "embedder = SentenceTransformer(EMBEDDING_MODEL, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095067a-c5f4-4922-bd01-21f69c25a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c4e76-0497-445e-913f-bfa01717d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets embed all inputs from our dataset and put them into a search index\n",
    "# IMPORTANT: don't get blocked by throughput on this part, reduce the size of the dataset if you need to\n",
    "\n",
    "test_emb = embedder.encode(ds[0]['input'])\n",
    "print(f'embedding type: {type(test_emb)}')\n",
    "print(f'embedding shape: {test_emb.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ef876-2505-4a11-a59d-9d1da7ea10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "\n",
    "ds_with_embeddings = ds.map(\n",
    "    lambda example: {\n",
    "        'embeddings': embedder.encode(example['input'])\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# 'embeddings': ctx_encoder(**ctx_tokenizer(example[\"line\"], return_tensors=\"pt\"))[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa08252-8d20-418e-a149-57dc9c5824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the embeddings in an in-memory FAISS index for fast semantic search\n",
    "ds_with_embeddings.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9acac6-2fdc-460e-b591-2be57ffdc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the query to find examples in the domain that you want to explore\n",
    "query_prompt = 'clothing, short, trousers, jacket, pants, shirt, tshirt, skirt'\n",
    "query_embedding = embedder.encode(query_prompt)\n",
    "\n",
    "# K is the number of\n",
    "K = 1000\n",
    "\n",
    "scores, samples = ds_with_embeddings.get_nearest_examples(\n",
    "    \"embeddings\", query_embedding, k=K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d43c4-6683-4b6f-a807-76becb8e9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(row['input'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945edb8a-3991-43a2-a00e-b7897f99313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b0c3b-8891-40b7-9f08-4af143fdaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41219c9-2dda-432d-b3b3-d16539d94164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create a HF dataset from the items we retrieved\n",
    "sampled_dataset = Dataset.from_dict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d6c94-1f80-4080-88ca-7f3a7637d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('data/sampled_dataset')\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "sampled_dataset.save_to_disk(output_path)\n",
    "print(f'saved dataset to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b49f6-fc03-4d04-b508-44a68f0d374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: do some additional manual filtering if needed to try to reduce your dataset down to the kinds of things you're really looking for\n",
    "# https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.DatasetDict.filter\n",
    "# IDEA: we could also filter with an LLM if we want to go faster / scale up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca551ffe-ae7f-4f6e-bfc7-8b98a20416fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're ready for the next step!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero-shot-ner-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
